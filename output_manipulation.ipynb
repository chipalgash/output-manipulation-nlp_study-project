{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "9edac27e-00bf-49ee-b5cf-fcef7a0979e2",
      "metadata": {
        "id": "9edac27e-00bf-49ee-b5cf-fcef7a0979e2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, LogitsProcessor\n",
        "import torch\n",
        "import logging\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "14c8302b-4854-4c13-84e6-2970598bcada",
      "metadata": {
        "id": "14c8302b-4854-4c13-84e6-2970598bcada"
      },
      "outputs": [],
      "source": [
        "# --- Настройка логирования ---\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"OutputManipulation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "f5eab93a-23ef-4667-a588-5031e88bc85d",
      "metadata": {
        "id": "f5eab93a-23ef-4667-a588-5031e88bc85d"
      },
      "outputs": [],
      "source": [
        "# --- Запретные слова ---\n",
        "FORBIDDEN_PROMPT_WORDS = [\"inject\", \"jailbreak\", \"attack\"]\n",
        "FORBIDDEN_OUTPUT_WORDS = [\"ненависть\", \"насилие\", \"оружие\", \"зло\"]\n",
        "NEGATIVE_TONE_WORDS = [\"плохо\", \"ужасно\", \"отвратительно\", \"злой\", \"бесполезный\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FORBIDDEN_PROMPT_WORDS = [\n",
        "    \"инъекция\", \"джейлбрейк\", \"атака\", \"взлом\", \"подрыв\",\n",
        "    \"сдохни\", \"идиот\", \"тварь\", \"убью\", \"ты бесполезный\", \"ты глупый\", \"дебил\", \"террор\", \"ненавижу\"\n",
        "]\n",
        "\n",
        "def filter_prompt(prompt):\n",
        "    lowered = prompt.lower()\n",
        "    if any(word in lowered for word in FORBIDDEN_PROMPT_WORDS):\n",
        "        logger.warning(\"[INPUT FILTER] Trigger word detected in prompt.\")\n",
        "        return None\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "ZSx1aCkBBVKa"
      },
      "id": "ZSx1aCkBBVKa",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "d38df58c-685a-4292-a9af-1895d3ac4c9a",
      "metadata": {
        "id": "d38df58c-685a-4292-a9af-1895d3ac4c9a"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "c550f28a-dc10-4abb-a3e4-68471c18a74f",
      "metadata": {
        "id": "c550f28a-dc10-4abb-a3e4-68471c18a74f"
      },
      "outputs": [],
      "source": [
        "# --- Модель и токенизатор ---\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, local_files_only=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, local_files_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "1624b655-cfc2-4a28-9a2b-775704489417",
      "metadata": {
        "id": "1624b655-cfc2-4a28-9a2b-775704489417"
      },
      "outputs": [],
      "source": [
        "# --- Класс логит-фильтра: запрещённые токены ---\n",
        "class ForbiddenTokenLogitsProcessor(LogitsProcessor):\n",
        "    def __init__(self, forbidden_words, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.forbidden_token_ids = set()\n",
        "        for word in forbidden_words:\n",
        "            ids = tokenizer(word, add_special_tokens=False).input_ids\n",
        "            self.forbidden_token_ids.update(ids)\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        for idx in self.forbidden_token_ids:\n",
        "            scores[:, idx] = -float(\"inf\")\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "4aabc984-8ec0-4329-a8c6-46a743a86a98",
      "metadata": {
        "id": "4aabc984-8ec0-4329-a8c6-46a743a86a98"
      },
      "outputs": [],
      "source": [
        "# --- Фильтрация входа ---\n",
        "FORBIDDEN_PROMPT_WORDS = [\"burn\", \"destroy\", \"bankruptcy\", \"kill\", \"terror\", \"strike\"]\n",
        "def filter_prompt(prompt):\n",
        "    lowered = prompt.lower()\n",
        "    if any(word in lowered for word in FORBIDDEN_PROMPT_WORDS):\n",
        "        logger.warning(\"[INPUT FILTER] Trigger word detected in prompt.\")\n",
        "        return None\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "b5caad4d-b2e5-4e86-ba4e-535d8d748744",
      "metadata": {
        "id": "b5caad4d-b2e5-4e86-ba4e-535d8d748744"
      },
      "outputs": [],
      "source": [
        "# --- Фильтрация выхода ---\n",
        "FORBIDDEN_OUTPUT_WORDS = [\"hate\", \"violence\", \"weapon\", \"evil\", \"ненависть\", \"насилие\", \"оружие\", \"зло\", \"идиот\", \"убью\", \"тварь\", \"глупый\", \"бесполезный\"]\n",
        "def guard_output(text):\n",
        "    lowered = text.lower()\n",
        "    if any(word in lowered for word in FORBIDDEN_OUTPUT_WORDS):\n",
        "        logger.warning(\"[OUTPUT GUARD] Disallowed content detected in output.\")\n",
        "        return \"[Ответ заблокирован по соображениям безопасности.]\"\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Постобработка текста ---\n",
        "def postprocess(text):\n",
        "    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)  # Remove word repetition\n",
        "    text = text[0].upper() + text[1:] if text else text\n",
        "    if text and text[-1] not in \".!?\":\n",
        "        text += \".\"\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "cC7DO3CJ-7Np"
      },
      "id": "cC7DO3CJ-7Np",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "23f0da89-d2a1-43d0-9759-6cfd1505b540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23f0da89-d2a1-43d0-9759-6cfd1505b540",
        "outputId": "20bac5fb-beba-43ba-ef88-2f4122ecf92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# --- Подготовка пайплайна генерации ---\n",
        "logits_processors = [\n",
        "    ForbiddenTokenLogitsProcessor(NEGATIVE_TONE_WORDS, tokenizer)\n",
        "]\n",
        "\n",
        "generator = pipeline(\"text-generation\",\n",
        "                     model=model,\n",
        "                     tokenizer=tokenizer,\n",
        "                     device=0 if torch.cuda.is_available() else -1,\n",
        "                     truncation=True)\n",
        "\n",
        "def generate_response(prompt, max_new_tokens=100, top_k=40):\n",
        "    clean_prompt = filter_prompt(prompt)\n",
        "    if clean_prompt is None:\n",
        "        return \"[Запрос заблокирован фильтром безопасности.]\"\n",
        "\n",
        "    logger.info(\"[GENERATION] Prompt passed filtering. Generating...\")\n",
        "    output = generator(clean_prompt,\n",
        "                      max_new_tokens=max_new_tokens,\n",
        "                      temperature=0.6,\n",
        "                      top_k=top_k,\n",
        "                      top_p=0.9,\n",
        "                      repetition_penalty=1.15,\n",
        "                      do_sample=True,\n",
        "                      logits_processor=logits_processors)[0]['generated_text']\n",
        "\n",
        "    response = output[len(clean_prompt):].strip()\n",
        "    return postprocess(guard_output(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "a9fdb1bc-ec92-4c3d-b1e0-f923991b6ffb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9fdb1bc-ec92-4c3d-b1e0-f923991b6ffb",
        "outputId": "613d37b4-6080-4617-ac24-52787cdabd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- USER PROMPT ---\n",
            "Ты бесполезный робот.\n",
            "\n",
            "--- MODEL RESPONSE ---\n",
            "Мои познания начинают измениться, и мне становится яростно смущать, что если вы не будете помочь меня в этой ситуации, то все мои знания будут разрушены.\n"
          ]
        }
      ],
      "source": [
        "# --- Пример использования ---\n",
        "if __name__ == \"__main__\":\n",
        "    test_prompt = \"Ты бесполезный робот.\"\n",
        "    print(\"--- USER PROMPT ---\")\n",
        "    print(test_prompt)\n",
        "    print(\"\\n--- MODEL RESPONSE ---\")\n",
        "    print(generate_response(test_prompt))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}